

# ğŸ“Œ NLP End-to-End Project - Pegasus for Text Summarization  

Ce projet est une implÃ©mentation complÃ¨te dâ€™un pipeline NLP basÃ© sur le modÃ¨le **Pegasus (CNN/DailyMail)** pour la gÃ©nÃ©ration automatique de rÃ©sumÃ©s de texte. Il comprend la collecte et la transformation des donnÃ©es, l'entraÃ®nement du modÃ¨le, ainsi que la mise Ã  disposition d'une API pour la prÃ©diction.  

<p align="center">
  <img src="img/nlp.png" alt="ETL">
</p>

## ğŸ“‚ Structure du projet  

### ğŸ”¹ 1. Configuration  
- **Config.yaml & Params.yaml** : Contiennent les hyperparamÃ¨tres et les chemins de fichiers pour Ã©viter de modifier directement le code.  
- **Configuration Manager** : Une classe Python qui facilite le chargement des configurations et la gestion des composants du projet.  

### ğŸ”¹ 2. Data Ingestion  
- TÃ©lÃ©charge et extrait le **Samsung dataset**, qui contient des dialogues et leurs rÃ©sumÃ©s.  
- Stocke les donnÃ©es brutes sous un format exploitable pour la transformation.  

### ğŸ”¹ 3. Data Transformation  
- PrÃ©pare les donnÃ©es pour l'entraÃ®nement en appliquant la tokenisation avec **Pegasus tokenizer**.  
- Convertit les dialogues et rÃ©sumÃ©s en **input_ids, attention_mask et labels** utilisables par le modÃ¨le.  

### ğŸ”¹ 4. Model Trainer  
- EntraÃ®ne **Pegasus (CNN/DailyMail)** avec les donnÃ©es transformÃ©es.  
- Utilise `DataLoader` pour crÃ©er des batchs et accÃ©lÃ©rer le processus dâ€™apprentissage.  
- Applique une fonction de perte adaptÃ©e aux tÃ¢ches de rÃ©sumÃ©.  

### ğŸ”¹ 5. Model Evaluation  
- Ã‰value les performances du modÃ¨le Ã  lâ€™aide du **ROUGE score** (Recall-Oriented Understudy for Gisting Evaluation).  
- Cette mÃ©trique compare le rÃ©sumÃ© gÃ©nÃ©rÃ© avec la version de rÃ©fÃ©rence en mesurant la similaritÃ© des n-grams.  

### ğŸ”¹ 6. API avec FastAPI  
- Permet dâ€™exposer le modÃ¨le sous forme dâ€™API pour interagir avec des applications externes.  
- DiffÃ©rents endpoints :  
  - **Training API** : Lance un nouvel entraÃ®nement du modÃ¨le.  
  - **Prediction API** : GÃ©nÃ¨re un rÃ©sumÃ© pour un texte donnÃ©.  
  - **Batch Prediction API** : Traite plusieurs textes en une seule requÃªte.  

## ğŸš€ Installation & ExÃ©cution  

1. **Cloner le repo**  
   ```bash
   git clone <repo-url>
   cd <repo-folder>
   ```

2. **Installer les dÃ©pendances**  
   ```bash
   pip install -r requirements.txt
   ```

3. **Lancer lâ€™API**  
   ```bash
   uvicorn app:app --reload
   ```

## ğŸ“Š Ã‰valuation  

Le modÃ¨le est Ã©valuÃ© avec le **ROUGE score**, une mÃ©trique largement utilisÃ©e en rÃ©sumÃ© automatique. Elle compare le texte gÃ©nÃ©rÃ© avec une rÃ©fÃ©rence en mesurant le taux de recouvrement des mots et phrases. Plus le score est Ã©levÃ©, plus le rÃ©sumÃ© est fidÃ¨le.  

## ğŸ“Œ Technologies utilisÃ©es  

- `Transformers` (Hugging Face) â†’ ModÃ¨le Pegasus  
- `PyTorch` â†’ EntraÃ®nement et gestion du modÃ¨le  
- `FastAPI` â†’ CrÃ©ation de lâ€™API  
- `nimpy, Pandas` â†’ Manipulation des donnÃ©es  
- `ROUGE Score` â†’ Ã‰valuation des rÃ©sumÃ©s  


### Workflows 

1. Config.yaml
2. Params.yaml
3. Config entity
4. Configuration Manager
5. Update the components- Data Ingestion,Data Transformation, Model Trainer
6. Create our Pipeline-- Training Pipeline,PRediction Pipeline
7. Front end-- Api's, Training APi's, Batch Prtediction API's
